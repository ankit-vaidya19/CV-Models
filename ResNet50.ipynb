{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "f4zUq8SjiQtz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "EtUbaiBTeyt2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')/255.0\n",
        "x_test = x_test.astype('float32')/255.0"
      ],
      "metadata": {
        "id": "c25eojSxjKcn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(0.9*len(x_train))\n",
        "x_train1 = x_train[:split]\n",
        "y_train1 = y_train[:split]\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]"
      ],
      "metadata": {
        "id": "-PQ8S2n-jKfD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train1.shape)\n",
        "print(y_train1.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyvyX8UgjKl9",
        "outputId": "b2f0f593-fcbe-4b14-c180-b18c8953b0d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 32, 32, 3)\n",
            "(45000, 1)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(x,f,filters):\n",
        "  F1,F2,F3 = filters\n",
        "  x_skip = x\n",
        "  x = layers.Conv2D(filters = F1,kernel_size = (1,1),strides = (1,1),padding = 'valid')(x)\n",
        "  x = layers.BatchNormalization()(x,training = True)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filters = F2,kernel_size = (f,f),strides = (1,1),padding = 'same')(x)\n",
        "  x = layers.BatchNormalization()(x,training = True)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filters = F3,kernel_size = (1,1),strides = (1,1),padding = 'valid')(x)\n",
        "  x = layers.BatchNormalization()(x,training = True)\n",
        "\n",
        "  x = layers.Add()([x,x_skip])\n",
        "  x = layers.Activation('relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "ysR21Uglmxof"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x,f,filters,s = 2):\n",
        "  F1,F2,F3 = filters\n",
        "  x_skip = x\n",
        "  x = layers.Conv2D(filters = F1,kernel_size = (1,1),strides = (s,s),padding = 'valid')(x)\n",
        "  x = layers.BatchNormalization()(x,training = True)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filters = F2,kernel_size = (f,f),strides = (1,1),padding = 'same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filters = F3,kernel_size = (1,1),strides = (1,1),padding = 'valid')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  \n",
        "  x_skip = layers.Conv2D(filters = F3,kernel_size = (1,1),strides = (s,s),padding = 'valid')(x_skip)\n",
        "  x_skip = layers.BatchNormalization()(x_skip)\n",
        "\n",
        "  x = layers.Add()([x,x_skip])\n",
        "  x = layers.Activation('relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "_tk0turamxwh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = (32,32,3))\n",
        "x = layers.ZeroPadding2D((3,3))(inputs)\n",
        "x = layers.Conv2D(64,kernel_size = (7,7),strides = (2,2))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.MaxPooling2D(pool_size = (3,3),strides = (2,2))(x)\n",
        "\n",
        "x = conv_block(x,3,filters = [64,64,256],s = 1)\n",
        "x = identity_block(x,3,[64,64,256])\n",
        "x = identity_block(x,3,[64,64,256])\n",
        "\n",
        "x = conv_block(x,3,[128,128,512],2)\n",
        "x = identity_block(x,3,[128,128,512])\n",
        "x = identity_block(x,3,[128,128,512])\n",
        "x = identity_block(x,3,[128,128,512])\n",
        "\n",
        "x = conv_block(x,3,[256,256,1024],2)\n",
        "x = identity_block(x,3,[256,256,1024])\n",
        "x = identity_block(x,3,[256,256,1024])\n",
        "x = identity_block(x,3,[256,256,1024])\n",
        "x = identity_block(x,3,[256,256,1024])\n",
        "x = identity_block(x,3,[256,256,1024])\n",
        "\n",
        "x = conv_block(x,3,[512,512,2048],2)\n",
        "x = identity_block(x,3,[512,512,2048])\n",
        "x = identity_block(x,3,[512,512,2048])\n",
        "\n",
        "x = layers.AveragePooling2D(pool_size = (1,1))(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "output = layers.Dense(10,activation = 'softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs = inputs,outputs = output)"
      ],
      "metadata": {
        "id": "2iX-J2LnkHrM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7UDIUdUkHtn",
        "outputId": "aacb84aa-077d-4021-9462-6a19ea62a594"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 64)   9472        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 64)  256         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 64)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 7, 7, 64)     0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 7, 7, 64)     4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 7, 7, 64)     36928       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 7, 7, 256)    16640       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 7, 7, 256)    16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 7, 7, 256)   1024        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 7, 7, 256)   1024        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 7, 7, 256)    0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 7, 7, 256)    0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 7, 7, 64)     16448       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 7, 7, 64)     36928       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 7, 7, 256)    16640       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 7, 7, 256)   1024        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 7, 7, 256)    0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 7, 7, 256)    0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 7, 7, 64)     16448       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 7, 7, 64)     36928       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 7, 7, 256)    16640       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 7, 7, 256)   1024        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 7, 7, 256)    0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 7, 7, 256)    0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 128)    32896       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 128)   512         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 4, 4, 128)   512         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 4, 4, 512)    131584      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 4, 4, 512)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 4, 4, 128)    65664       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 4, 4, 128)   512         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 4, 4, 128)   512         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 4, 4, 512)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 4, 4, 128)    65664       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 4, 4, 128)   512         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 4, 4, 128)   512         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 4, 4, 512)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 4, 4, 128)    65664       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 4, 4, 128)   512         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 4, 4, 128)   512         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_23[0][0]', \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 4, 4, 512)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 2, 2, 256)    131328      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 2, 2, 1024)   525312      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 2, 2, 1024)   0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 2, 2, 1024)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 2, 2, 1024)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 2, 2, 1024)   0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 2, 2, 1024)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 2, 2, 1024)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 1, 1, 512)    524800      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 2048)   1050624     ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 2048)   2099200     ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 1, 1, 2048)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 1, 1, 512)    1049088     ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 2048)   1050624     ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_49[0][0]', \n",
            "                                                                  'activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 1, 1, 2048)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 512)    1049088     ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 1, 1, 2048)   1050624     ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_52[0][0]', \n",
            "                                                                  'activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 1, 1, 2048)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_48[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           20490       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = keras.optimizers.SGD(learning_rate = 0.1,momentum = 0.9,),\n",
        "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "4vDMSgcWkHxI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',factor = 0.1,patience = 5,mode = 'max',cooldown = 0)"
      ],
      "metadata": {
        "id": "st8gvD_MyxH0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train1,y_train1,batch_size = 256,epochs = 100,callbacks = [lr_reducer],validation_data = (x_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuVD083EyxLd",
        "outputId": "c4323bb3-1687-4c37-824c-879fd1f448d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 31s 114ms/step - loss: 6.2405 - accuracy: 0.1293 - val_loss: 6.0876 - val_accuracy: 0.1082 - lr: 0.1000\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 2.7744 - accuracy: 0.2338 - val_loss: 2.8599 - val_accuracy: 0.2336 - lr: 0.1000\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 2.1395 - accuracy: 0.3023 - val_loss: 1.9462 - val_accuracy: 0.3110 - lr: 0.1000\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.8551 - accuracy: 0.3454 - val_loss: 1.8275 - val_accuracy: 0.3484 - lr: 0.1000\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.7194 - accuracy: 0.3842 - val_loss: 1.7259 - val_accuracy: 0.3738 - lr: 0.1000\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.6216 - accuracy: 0.4131 - val_loss: 1.6141 - val_accuracy: 0.4100 - lr: 0.1000\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.5392 - accuracy: 0.4347 - val_loss: 1.5666 - val_accuracy: 0.4322 - lr: 0.1000\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.4892 - accuracy: 0.4561 - val_loss: 1.4873 - val_accuracy: 0.4522 - lr: 0.1000\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.4335 - accuracy: 0.4759 - val_loss: 1.4364 - val_accuracy: 0.4736 - lr: 0.1000\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.3876 - accuracy: 0.4930 - val_loss: 1.4168 - val_accuracy: 0.4886 - lr: 0.1000\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.3462 - accuracy: 0.5090 - val_loss: 1.3871 - val_accuracy: 0.5052 - lr: 0.1000\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.3082 - accuracy: 0.5249 - val_loss: 1.3365 - val_accuracy: 0.5180 - lr: 0.1000\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.2651 - accuracy: 0.5397 - val_loss: 1.3156 - val_accuracy: 0.5230 - lr: 0.1000\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.2321 - accuracy: 0.5529 - val_loss: 1.3150 - val_accuracy: 0.5224 - lr: 0.1000\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.1882 - accuracy: 0.5710 - val_loss: 1.2830 - val_accuracy: 0.5296 - lr: 0.1000\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.1562 - accuracy: 0.5824 - val_loss: 1.2663 - val_accuracy: 0.5482 - lr: 0.1000\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 1.1261 - accuracy: 0.5942 - val_loss: 1.2577 - val_accuracy: 0.5438 - lr: 0.1000\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.0806 - accuracy: 0.6120 - val_loss: 1.2852 - val_accuracy: 0.5428 - lr: 0.1000\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.0483 - accuracy: 0.6261 - val_loss: 1.2253 - val_accuracy: 0.5568 - lr: 0.1000\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 1.0126 - accuracy: 0.6369 - val_loss: 1.2519 - val_accuracy: 0.5536 - lr: 0.1000\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.9799 - accuracy: 0.6498 - val_loss: 1.2244 - val_accuracy: 0.5670 - lr: 0.1000\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.9499 - accuracy: 0.6579 - val_loss: 1.2322 - val_accuracy: 0.5602 - lr: 0.1000\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.9120 - accuracy: 0.6730 - val_loss: 1.2290 - val_accuracy: 0.5740 - lr: 0.1000\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.8713 - accuracy: 0.6887 - val_loss: 1.2382 - val_accuracy: 0.5730 - lr: 0.1000\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.8379 - accuracy: 0.6986 - val_loss: 1.2554 - val_accuracy: 0.5752 - lr: 0.1000\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.7985 - accuracy: 0.7144 - val_loss: 1.2996 - val_accuracy: 0.5694 - lr: 0.1000\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.7555 - accuracy: 0.7287 - val_loss: 1.2743 - val_accuracy: 0.5842 - lr: 0.1000\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.7180 - accuracy: 0.7427 - val_loss: 1.3451 - val_accuracy: 0.5752 - lr: 0.1000\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.6802 - accuracy: 0.7551 - val_loss: 1.2862 - val_accuracy: 0.5884 - lr: 0.1000\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.6515 - accuracy: 0.7651 - val_loss: 1.3386 - val_accuracy: 0.5852 - lr: 0.1000\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.6063 - accuracy: 0.7818 - val_loss: 1.4462 - val_accuracy: 0.5732 - lr: 0.1000\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.5764 - accuracy: 0.7918 - val_loss: 1.4140 - val_accuracy: 0.5836 - lr: 0.1000\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.5334 - accuracy: 0.8077 - val_loss: 1.4488 - val_accuracy: 0.5882 - lr: 0.1000\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.5020 - accuracy: 0.8192 - val_loss: 1.4876 - val_accuracy: 0.5854 - lr: 0.1000\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.3519 - accuracy: 0.8750 - val_loss: 1.5954 - val_accuracy: 0.6028 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.2357 - accuracy: 0.9186 - val_loss: 1.7620 - val_accuracy: 0.6032 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.2006 - accuracy: 0.9310 - val_loss: 1.9371 - val_accuracy: 0.5966 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1776 - accuracy: 0.9388 - val_loss: 2.0575 - val_accuracy: 0.5970 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1624 - accuracy: 0.9441 - val_loss: 2.1580 - val_accuracy: 0.5976 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1442 - accuracy: 0.9512 - val_loss: 2.2908 - val_accuracy: 0.5968 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1342 - accuracy: 0.9545 - val_loss: 2.3690 - val_accuracy: 0.5914 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1171 - accuracy: 0.9617 - val_loss: 2.3943 - val_accuracy: 0.5948 - lr: 1.0000e-03\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1125 - accuracy: 0.9635 - val_loss: 2.4206 - val_accuracy: 0.5932 - lr: 1.0000e-03\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1105 - accuracy: 0.9639 - val_loss: 2.4440 - val_accuracy: 0.5920 - lr: 1.0000e-03\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1084 - accuracy: 0.9647 - val_loss: 2.4642 - val_accuracy: 0.5940 - lr: 1.0000e-03\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1096 - accuracy: 0.9652 - val_loss: 2.4805 - val_accuracy: 0.5918 - lr: 1.0000e-03\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1024 - accuracy: 0.9673 - val_loss: 2.4834 - val_accuracy: 0.5922 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1028 - accuracy: 0.9669 - val_loss: 2.4854 - val_accuracy: 0.5914 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1021 - accuracy: 0.9673 - val_loss: 2.4875 - val_accuracy: 0.5918 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 2.4873 - val_accuracy: 0.5920 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1023 - accuracy: 0.9672 - val_loss: 2.4943 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1021 - accuracy: 0.9674 - val_loss: 2.4923 - val_accuracy: 0.5930 - lr: 1.0000e-05\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1008 - accuracy: 0.9673 - val_loss: 2.4916 - val_accuracy: 0.5924 - lr: 1.0000e-05\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1010 - accuracy: 0.9670 - val_loss: 2.4922 - val_accuracy: 0.5926 - lr: 1.0000e-05\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1006 - accuracy: 0.9688 - val_loss: 2.4921 - val_accuracy: 0.5928 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 2.4888 - val_accuracy: 0.5924 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1010 - accuracy: 0.9679 - val_loss: 2.4914 - val_accuracy: 0.5922 - lr: 1.0000e-06\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1025 - accuracy: 0.9675 - val_loss: 2.4942 - val_accuracy: 0.5930 - lr: 1.0000e-06\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1017 - accuracy: 0.9680 - val_loss: 2.4917 - val_accuracy: 0.5918 - lr: 1.0000e-06\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1014 - accuracy: 0.9680 - val_loss: 2.4918 - val_accuracy: 0.5918 - lr: 1.0000e-06\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1012 - accuracy: 0.9686 - val_loss: 2.4899 - val_accuracy: 0.5920 - lr: 1.0000e-06\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1015 - accuracy: 0.9675 - val_loss: 2.4905 - val_accuracy: 0.5914 - lr: 1.0000e-07\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1024 - accuracy: 0.9671 - val_loss: 2.4874 - val_accuracy: 0.5920 - lr: 1.0000e-07\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1034 - accuracy: 0.9671 - val_loss: 2.4924 - val_accuracy: 0.5926 - lr: 1.0000e-07\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1036 - accuracy: 0.9674 - val_loss: 2.4950 - val_accuracy: 0.5924 - lr: 1.0000e-07\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1045 - accuracy: 0.9665 - val_loss: 2.4907 - val_accuracy: 0.5926 - lr: 1.0000e-07\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1010 - accuracy: 0.9685 - val_loss: 2.4925 - val_accuracy: 0.5928 - lr: 1.0000e-08\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1034 - accuracy: 0.9665 - val_loss: 2.4903 - val_accuracy: 0.5930 - lr: 1.0000e-08\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1025 - accuracy: 0.9674 - val_loss: 2.4936 - val_accuracy: 0.5930 - lr: 1.0000e-08\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1017 - accuracy: 0.9678 - val_loss: 2.4925 - val_accuracy: 0.5928 - lr: 1.0000e-08\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1017 - accuracy: 0.9678 - val_loss: 2.4907 - val_accuracy: 0.5922 - lr: 1.0000e-08\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1010 - accuracy: 0.9675 - val_loss: 2.4917 - val_accuracy: 0.5924 - lr: 1.0000e-09\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1025 - accuracy: 0.9672 - val_loss: 2.4936 - val_accuracy: 0.5920 - lr: 1.0000e-09\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1016 - accuracy: 0.9682 - val_loss: 2.4935 - val_accuracy: 0.5928 - lr: 1.0000e-09\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1007 - accuracy: 0.9674 - val_loss: 2.4887 - val_accuracy: 0.5920 - lr: 1.0000e-09\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1022 - accuracy: 0.9680 - val_loss: 2.4921 - val_accuracy: 0.5930 - lr: 1.0000e-09\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1018 - accuracy: 0.9674 - val_loss: 2.4936 - val_accuracy: 0.5928 - lr: 1.0000e-10\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1027 - accuracy: 0.9680 - val_loss: 2.4898 - val_accuracy: 0.5922 - lr: 1.0000e-10\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1056 - accuracy: 0.9666 - val_loss: 2.4924 - val_accuracy: 0.5932 - lr: 1.0000e-10\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1042 - accuracy: 0.9676 - val_loss: 2.4925 - val_accuracy: 0.5920 - lr: 1.0000e-10\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.0997 - accuracy: 0.9691 - val_loss: 2.4936 - val_accuracy: 0.5936 - lr: 1.0000e-10\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1018 - accuracy: 0.9677 - val_loss: 2.4948 - val_accuracy: 0.5924 - lr: 1.0000e-11\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1037 - accuracy: 0.9673 - val_loss: 2.4920 - val_accuracy: 0.5922 - lr: 1.0000e-11\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1034 - accuracy: 0.9669 - val_loss: 2.4897 - val_accuracy: 0.5918 - lr: 1.0000e-11\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.0992 - accuracy: 0.9679 - val_loss: 2.4875 - val_accuracy: 0.5924 - lr: 1.0000e-11\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1012 - accuracy: 0.9683 - val_loss: 2.4948 - val_accuracy: 0.5928 - lr: 1.0000e-11\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1035 - accuracy: 0.9664 - val_loss: 2.4938 - val_accuracy: 0.5928 - lr: 1.0000e-12\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1016 - accuracy: 0.9674 - val_loss: 2.4931 - val_accuracy: 0.5932 - lr: 1.0000e-12\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1030 - accuracy: 0.9677 - val_loss: 2.4922 - val_accuracy: 0.5934 - lr: 1.0000e-12\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1053 - accuracy: 0.9664 - val_loss: 2.4909 - val_accuracy: 0.5934 - lr: 1.0000e-12\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.0995 - accuracy: 0.9686 - val_loss: 2.4869 - val_accuracy: 0.5920 - lr: 1.0000e-12\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1026 - accuracy: 0.9674 - val_loss: 2.4870 - val_accuracy: 0.5920 - lr: 1.0000e-13\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1020 - accuracy: 0.9674 - val_loss: 2.4920 - val_accuracy: 0.5920 - lr: 1.0000e-13\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1028 - accuracy: 0.9676 - val_loss: 2.4943 - val_accuracy: 0.5924 - lr: 1.0000e-13\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1020 - accuracy: 0.9672 - val_loss: 2.4908 - val_accuracy: 0.5922 - lr: 1.0000e-13\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 16s 90ms/step - loss: 0.1010 - accuracy: 0.9681 - val_loss: 2.4901 - val_accuracy: 0.5920 - lr: 1.0000e-13\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1052 - accuracy: 0.9665 - val_loss: 2.4913 - val_accuracy: 0.5918 - lr: 1.0000e-14\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1014 - accuracy: 0.9681 - val_loss: 2.4952 - val_accuracy: 0.5926 - lr: 1.0000e-14\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1033 - accuracy: 0.9658 - val_loss: 2.4888 - val_accuracy: 0.5924 - lr: 1.0000e-14\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 16s 89ms/step - loss: 0.1021 - accuracy: 0.9666 - val_loss: 2.4917 - val_accuracy: 0.5926 - lr: 1.0000e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model.evaluate(x_test,y_test,batch_size = 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpiMN6bsTSaz",
        "outputId": "02554539-06ac-4ef6-fc3a-4421dfb5e095"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 2s 39ms/step - loss: 2.6275 - accuracy: 0.5866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7RUcwHwrTaqE",
        "outputId": "b6534b64-1eb0-44b0-a9ff-057aa99b2f1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4ZCYd2oMTa4y",
        "outputId": "e6774d85-fff6-4c13-af96-38b8fec41fa4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f90b03002b0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}